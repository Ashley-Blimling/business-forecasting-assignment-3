# -*- coding: utf-8 -*-
"""assignment3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CPZqgN2NBpn0tzBk3Dq-J7G1ycpHUUOv
"""

#Importing Modules
import numpy as np
import pandas as pd
import io
import gzip
import torch
import requests
import torch.nn as nn
import plotly.express as px
import torch.nn.functional as F
from torchvision import datasets, transforms
from torch.utils.data import Dataset, DataLoader, random_split

#My Custom Data Loader

def downloadData(url):
    response = requests.get(url)
    with gzip.GzipFile(fileobj=io.BytesIO(response.content), mode = "rb") as file:
        data = np.frombuffer(file.read(), dtype = np.uint8)
    return data

trainImages = downloadData("https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-images-idx3-ubyte.gz")[16:].reshape(-1, 28, 28)
trainLabels = downloadData("https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-labels-idx1-ubyte.gz")[8:]
testImages = downloadData("https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-images-idx3-ubyte.gz")[16:].reshape(-1, 28, 28)
testLabels = downloadData("https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-labels-idx1-ubyte.gz")[8:]

#Setting Transform to Tensor for Readability
transform = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor()])

class CustomFashionMNIST(Dataset):
  def __init__(self, images, labels, transform = transform):
        self.images = images
        self.labels = labels
        self.transform = transform

  def __len__(self):
    return len(self.labels)

  def __getitem__(self, idx):
    image = self.images[idx]
    label = self.labels[idx]
    return image, label

#Splitting FashionMNIST Data into Training and Testing Sets
trainSize = int(0.8 * len(customData))
testSize = len(customData) - trainSize

trainData, testData = random_split(FashionMNIST, [trainSize, testSize])

trainLoader = DataLoader(trainData, batch_size = 64) #Batch size is larger to try to increase accuracy.
testLoader = DataLoader(testData, batch_size = 64) #Batch size is larger to try to increase accuracy.

#Translating the Key for the FashionMNIST Data
labels = {
    0: "T-shirt/top",
    1: "Trouser",
    2: "Pullover",
    3: "Dress",
    4: "Coat",
    5: "Sandal",
    6: "Shirt",
    7: "Sneaker",
    8: "Bag",
    9: "Ankle boot"
}

#Getting the Image and Label (to check that our data look right when we sample).
idx = 1
image, label = trainData[idx]
print(f"This image is labeled as: {labels[label]}")
px.imshow(trainData.__getitem__(idx)[0].reshape(28, 28))

#My Neural Network (Also Based on Class 7)

class NeuralNet(nn.Module):
  def __init__(self): #Defining the components of my model.
    super(NeuralNet, self).__init__()
    self.flatten = nn.Flatten()
    self.linear_relu_model = nn.Sequential(nn.LazyLinear(10))

  def forward(self, x): #Constructing the sequencing of my model.
    x = self.flatten(x)
    output = self.linear_relu_model(x)
    return output

model = NeuralNet()

#Training Parameters
learning_rate = 1e-02
batch_size = 64 #Larger to try to increase accuracy.
epochs = 50
lossFunctionn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)

#For Training My Model
def trainLoop(dataloader, model, lossFunctionn, optimizer):
  size = len(dataloader.dataset)
  model.train()
  for batch, (X, y) in enumerate(dataloader):
    pred = model(X)
    loss = lossFunctionn(pred, y)
    loss.backward()
    optimizer.step()
    optimizer.zero_grad()
    if batch % 10 == 0: #Printing Progress
      loss, current = loss.item(), (batch + 1) * len(X)
      print(f"loss: {loss: > 7f} [{current: > 5d} / {size: > 5d}]")

#For Testing My Model
def testLoop(dataloader, model, lossFunctionn):
  model.eval()
  size = len(dataloader.dataset)
  numBatches = len(dataloader)
  testLoss, correct = 0, 0
  with torch.no_grad():
    for X, y in dataloader:
      pred = model(X)
      testLoss += lossFunctionn(pred, y).item()
      correct += (pred.argmax(1) == y).type(torch.float).sum().item()
  testLoss /= numBatches
  correct /= size
  print(f"Test Error: \n Accuracy: {(100*correct):>0.1f}%, Avg loss: {testLoss: > 8f} \n")

#Actually Training
for t in range(epochs):
  print(f"Epoch {t + 1}\n-------------------------------")
  trainLoop(trainLoader, model, lossFunctionn, optimizer)
  testLoop(testLoader, model, lossFunctionn)
  print("Done!")

#Saving my Model

EPOCH = epochs
PATH = "model.pt"
torch.save({"epoch": EPOCH, "model_state_dict": model.state_dict(), "optimizer_state_dict": optimizer.state_dict(), }, PATH)

#Import Script

PATH = "model.pt"
model = NeuralNet()
optimizer = torch.optim.SGD(model.parameters(), lr = 0.001, momentum = 0.9)

checkpoint = torch.load(PATH)
model.load_state_dict(checkpoint["model_state_dict"])
optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
EPOCH = checkpoint["epoch"]